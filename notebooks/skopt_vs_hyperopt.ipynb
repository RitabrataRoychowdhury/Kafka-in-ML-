{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skopt vs Hyperopt\n",
    "\n",
    "## Importing and preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "\n",
    "from time import time\n",
    "from hyperopt import hp, tpe, fmin, Trials\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from skopt import gbrt_minimize\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import log_loss\n",
    "from utils import FeatureTools\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  fnlwgt  education      marital_status  \\\n",
       "0   39         State-gov   77516  Bachelors       Never-married   \n",
       "1   50  Self-emp-not-inc   83311  Bachelors  Married-civ-spouse   \n",
       "2   38           Private  215646    HS-grad            Divorced   \n",
       "3   53           Private  234721       11th  Married-civ-spouse   \n",
       "4   28           Private  338409  Bachelors  Married-civ-spouse   \n",
       "\n",
       "          occupation   relationship   race  gender  capital_gain  \\\n",
       "0       Adm-clerical  Not-in-family  White    Male          2174   \n",
       "1    Exec-managerial        Husband  White    Male             0   \n",
       "2  Handlers-cleaners  Not-in-family  White    Male             0   \n",
       "3  Handlers-cleaners        Husband  Black    Male             0   \n",
       "4     Prof-specialty           Wife  Black  Female             0   \n",
       "\n",
       "   capital_loss  hours_per_week native_country  target  \n",
       "0             0              40  United-States       0  \n",
       "1             0              13  United-States       0  \n",
       "2             0              40  United-States       0  \n",
       "3             0              40  United-States       0  \n",
       "4             0              40           Cuba       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/adult.data\")\n",
    "df['target'] = (df['income_bracket'].apply(lambda x: '>50K' in x)).astype(int)\n",
    "df.drop('income_bracket', axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have coded a preprocessor class before that does the work for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the features column names are: ['age', 'workclass', 'fnlwgt', 'education', 'marital_status', 'occupation', 'relationship', 'race', 'gender', 'capital_gain', 'capital_loss', 'hours_per_week', 'native_country', 'education_occupation', 'native_country_occupation']\n",
      "the categorical columns are: ['workclass', 'education', 'marital_status', 'occupation', 'relationship', 'race', 'gender', 'native_country', 'education_occupation', 'native_country_occupation']\n"
     ]
    }
   ],
   "source": [
    "dataprocessor = pickle.load(open(\"data/dataprocessors/dataprocessor_0_.p\", \"rb\"))\n",
    "all_features = dataprocessor.colnames\n",
    "categorical_features = dataprocessor.cat_cols + dataprocessor.crossed_columns\n",
    "\n",
    "print(\"the features column names are: {}\".format(all_features))\n",
    "print(\"the categorical columns are: {}\".format(categorical_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the `dataprocessor` is already train, so we simply need to `transform`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>target</th>\n",
       "      <th>education_occupation</th>\n",
       "      <th>native_country_occupation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.301370</td>\n",
       "      <td>0</td>\n",
       "      <td>0.044302</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.02174</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.452055</td>\n",
       "      <td>1</td>\n",
       "      <td>0.048238</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.122449</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.287671</td>\n",
       "      <td>2</td>\n",
       "      <td>0.138113</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.493151</td>\n",
       "      <td>2</td>\n",
       "      <td>0.151068</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.150685</td>\n",
       "      <td>2</td>\n",
       "      <td>0.221488</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  workclass    fnlwgt  education  marital_status  occupation  \\\n",
       "0  0.301370          0  0.044302          0               0           0   \n",
       "1  0.452055          1  0.048238          0               1           1   \n",
       "2  0.287671          2  0.138113          1               2           2   \n",
       "3  0.493151          2  0.151068          2               1           2   \n",
       "4  0.150685          2  0.221488          0               1           3   \n",
       "\n",
       "   relationship  race  gender  capital_gain  capital_loss  hours_per_week  \\\n",
       "0             0     0       0       0.02174           0.0        0.397959   \n",
       "1             1     0       0       0.00000           0.0        0.122449   \n",
       "2             0     0       0       0.00000           0.0        0.397959   \n",
       "3             1     1       0       0.00000           0.0        0.397959   \n",
       "4             2     1       1       0.00000           0.0        0.397959   \n",
       "\n",
       "   native_country  target  education_occupation  native_country_occupation  \n",
       "0               0       0                     0                          0  \n",
       "1               0       0                     1                          1  \n",
       "2               0       0                     2                          2  \n",
       "3               0       0                     3                          2  \n",
       "4               1       0                     4                          3  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = dataprocessor.transform(df)\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np arrays\n",
    "X_train = train_data[[c for c in train_data.columns if c is not 'target']].values\n",
    "y_train = train_data['target'].values\n",
    "\n",
    "# lgb Dataset object\n",
    "lgtrain = lgb.Dataset(X_train,\n",
    "    label=y_train,\n",
    "    feature_name=all_features,\n",
    "    categorical_feature=categorical_features,\n",
    "    free_raw_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model and fit params\n",
    "params = dict(learning_rate=0.01,\n",
    "    num_boost_round=300,\n",
    "    num_leaves = 255,\n",
    "    verbose=-1,\n",
    "    is_unbalance=True)\n",
    "fit_params = dict(feature_name=all_features,\n",
    "        categorical_feature=categorical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. First experiment. Sklearn wrap up vs lightgbm methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.932429075241089\n"
     ]
    }
   ],
   "source": [
    "clf = lgb.LGBMClassifier(**params, silent=True)\n",
    "start = time()\n",
    "score = cross_val_score(clf,\n",
    "    X_train, y_train,\n",
    "    scoring='neg_log_loss',\n",
    "    cv=StratifiedKFold(random_state=1981),\n",
    "    fit_params=fit_params)\n",
    "sklearn_runtime = time() - start\n",
    "print(sklearn_runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.038502931594849\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "cv_result = lgb.cv(params,\n",
    "    lgtrain,\n",
    "    metrics='binary_logloss',\n",
    "    nfold=3,\n",
    "    stratified=True, \n",
    "    seed=1981)\n",
    "lightgbm_runtime = time() - start\n",
    "print(lightgbm_runtime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LightGBM methods seem to be a bit faster. Let's now compare `Hyperopt` and `Skopt`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperopt vs Skopt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing to comment is that while Hyperopt offers the `hp.quniform(label, low, high, q)` parameter expressions, there is not such a thing for Skopt. One has `Categorical`, but you have to pass all values. In other words, When using hyperopt one could use:\n",
    "\n",
    "    'num_boost_round': hp.quniform('num_boost_round', 50, 500, 20)\n",
    "\n",
    "but when using Skopt one would have to do:\n",
    "\n",
    "    Categorical(np.arange(50, 500, 20))\n",
    "    \n",
    "Because I want to keep the comparison as light and direct as possible, I will just use `Real` parameters with uniform distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Hyperopt\n",
    "\n",
    "With Hyperopt we will use the [TPE](https://papers.nips.cc/paper/4443-algorithms-for-hyper-parameter-optimization.pdf) algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_space = {\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.01, 0.3),\n",
    "    'min_child_weight': hp.uniform('min_child_weight', 0.1, 10),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1.),\n",
    "    'subsample': hp.uniform('subsample', 0.5, 1.),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:39<00:00,  1.18it/s, best loss: 0.28343034788381305]\n"
     ]
    }
   ],
   "source": [
    "def objective(params):\n",
    "    clf = lgb.LGBMClassifier(**params, is_unbalance=True, verbose=-1, silent=True)\n",
    "    score = cross_val_score(clf,\n",
    "        X_train, y_train,\n",
    "        scoring='f1',\n",
    "        cv=StratifiedKFold(random_state=3),\n",
    "        fit_params=fit_params).mean()\n",
    "    return 1-score\n",
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=hp_space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=50,\n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. SKopt\n",
    "\n",
    "Since TPE is a Bayesian method we will first compare with the `BayesSearchCV` method in `Skopt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "hh_space = dict(\n",
    "        learning_rate = Real(0.01, 0.3),\n",
    "        min_child_weight = Real(0.1, 10),\n",
    "        colsample_bytree= Real(0.5, 1.),\n",
    "        subsample=Real(0.5, 1.),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63.14497208595276\n"
     ]
    }
   ],
   "source": [
    "clf = lgb.LGBMClassifier(is_unbalance=True, verbose=-1, silent=True)\n",
    "start = time()\n",
    "opt = BayesSearchCV(clf,\n",
    "    search_spaces=hh_space,\n",
    "    scoring='f1',\n",
    "    cv=StratifiedKFold(random_state=3),\n",
    "    fit_params=fit_params,\n",
    "    n_iter=50,\n",
    "    n_jobs=-1)\n",
    "opt.fit(X_train, y_train)\n",
    "skopt_bayes_runtime = time()-start\n",
    "print(skopt_bayes_runtime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Skopt`'s seems to be a significantly slower than hyperopt even with no verbosity. Let's see if performs better:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best SKOPT F1 score: 0.7174372197995806\n"
     ]
    }
   ],
   "source": [
    "print('best SKOPT F1 score: {}'.format(opt.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which is almost identical to the one obtained with `Hyperopt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best HYPEROPT F1 score: 0.716569652116187\n"
     ]
    }
   ],
   "source": [
    "# Remember hyperopt minimises 1-score. \n",
    "print('best HYPEROPT F1 score: {}'.format(1-trials.best_trial['result']['loss']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The conclusion at this stage is that `Hyperopt` is faster than `Skopt` with the same performance. However, the `TPE` algorithm is a tree based algorithm, so let's also compare with the `gbrt_minimize` method (Sequential optimization using gradient boosted trees) in `Skopt`. Here the syntax is a bit different to that of `BayesSearchCV`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the space has to be tuples like these\n",
    "hh_space_gbrt  = [Real(0.01, 0.3, 'uniform', name='learning_rate'),\n",
    "          Real(0.1, 10, 'uniform', name='min_child_weight'),\n",
    "          Real(0.5, 1., 'uniform', name='colsample_bytree'),\n",
    "          Real(0.5, 1., 'uniform', name='subsample')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's adapt the objective\n",
    "def gbrt_objective(params):\n",
    "    tmp_params = {}\n",
    "    tmp_params['learning_rate'], tmp_params['min_child_weight'], \\\n",
    "    tmp_params['colsample_bytree'], tmp_params['subsample'], = params[0], params[1], params[2], params[3]\n",
    "    clf = lgb.LGBMClassifier(**tmp_params, is_unbalance=True, verbose=-1, silent=True)\n",
    "    score = cross_val_score(clf,\n",
    "        X_train, y_train,\n",
    "        scoring='f1',\n",
    "        cv=StratifiedKFold(random_state=3),\n",
    "        fit_params=fit_params).mean()\n",
    "    return 1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54.64228296279907\n"
     ]
    }
   ],
   "source": [
    "start=time()\n",
    "sk_best = gbrt_minimize(gbrt_objective,\n",
    "    hh_space_gbrt,\n",
    "    n_calls=50,\n",
    "    verbose=False,\n",
    "    n_jobs=-1)\n",
    "skopt_gbrt_runtime = time()-start\n",
    "print(skopt_gbrt_runtime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faster than `BayesSearchCV`, but still, slower than `Hyperopt`. Let's see if the results are any better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best SKOPT GBRT F1 score: 0.7173483496134895\n"
     ]
    }
   ],
   "source": [
    "print('best SKOPT GBRT F1 score: {}'.format(1-sk_best.fun))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONCLUSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Hyperopt`'s TPE performs as good as Skopt `gbrt_minimize` and `BayesSearchCV` methods and is significantly faster."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
